<aside>
🔍 **웹 크롤러 설계**

</aside>

### ⭐️ 웹 크롤러

: 검색 엔진에서 널리 쓰는 기술. 웹에 새로 올라오거나 갱신된 콘텐츠를 찾아내는 것이 주된 목적

- 용도
    - 검색 엔진 인덱싱

  웹 페이지를 모아 검색 엔진을 위한 로컬 인덱스 생성 (ex Googlebot)

    - 웹 아카이빙

  나중에 사용할 목적으로  장기보관하기 위해 웹에서 정보를 모으는 절차
  (국립 도서관에서 사용)

    - 웹 마이닝

  유용한 정보를 판단하여 추출

    - 웹 모니터링

  저작권이나 상표권이 침해되는 사례를 모니터링


### ⭐️ 요구사항

- 검색 엔진 인덱싱에 사용
- 매달 10억개의 웹 페이지를 다운로드
- QPS(초당 서버가 응답할 수 있는 쿼리의 수)= 10억 → 대략 400페이지 /초
- 최대 (Peak) QPS = 2*QPS = 800
- 웹 페이지의 크기 평균은 500k
- 5년간 30PB의 저장용량 필요

### ⭐️ 개략적 설계

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/4eb17d17-9fd9-456b-9cd6-805a7036e822/d339268b-0522-48bb-bd29-7e7551d292db/Untitled.png)

- 시작 URL을 무엇으로 쓸 것인가?

  : 웹 크롤러가 크롤링을 시작하는 출발점
  → 가능한 한 많은 링크를 탐색할 수 있도록 하는 URL 고려 (분할정복의 전략 사용)

- 도메인 이름이 붙은 모든 페이지의 URL을 시작 URL로 사용
- 주제별로 다른 URL 사용
- 어떤 루트를 가져갈 것인가?

- 중복 콘텐츠인가?

  : 29%의 중복된 데이터를 저장하여 리소스 낭비를 방지하기 위해 페이지 해시값을 비교

- 콘텐츠 저장소

  : HTML 문서 보관 시스템

- 대부분의 콘텐츠는 디스크에 저장
- 인기 콘텐츠는 메모리상에 존재
- 검색엔진에서 사용되는 모든 문서들은 이렇게 저장되는걸까?

- 이미 방문한 URL?

  : 이미 방문한 URL이나 미수집 URL 저장소에 보관된 URL을 추적할 수 있도록 하는 자료 구조

→ 블룸 필터, 해시 테이블

전체 작업 흐름

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/4eb17d17-9fd9-456b-9cd6-805a7036e822/481cdf02-2049-425d-a195-4fc7a62d9dc9/Untitled.png)

### ⭐️ 상세 설계

- DFS / BFS

→ BFS을 대표적으로 사용 (그래프 크기가 클 경우 어느 정도로 깊숙이 가게 될지 가늠하기 어려워서)

- 문제점
    - 한 페이지에서 나오는 링크가 같은 서버로 돌아가는데, 병렬로 처리하게 된다면 디도스 걸림
    - URL 간에 우선순위를 두지 않음
      → 웹 페이지는 페이지 순위, 사용자 트래픽의 양, 업데이트 빈도 등 여러 가지 척도에 비추어 우선순위를 구별해야 함

- 미수집 URL 저장소

  : 신선도, 우선순위를 어떻게 만들까

- 예의
    - “동일 웹 사이트에 대해서는 한 번에 한 페이지만 요청한다”
- 우선순위

  : 순위결정장치를 통해 URL 우선순위를 정하는 컴포넌트

전면큐 : 우선순위 결정 과정 처리

후면 큐 : 크롤러가 예의 바르게 동작하도록 보증

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/4eb17d17-9fd9-456b-9cd6-805a7036e822/0eafaeea-e1e0-4f06-8e70-d5539d32c2b4/Untitled.png)

- 신선도

  : 데이터의 신선함을 위해 이미 다운로드한 페이지라고 해도 주기적으로 재수집할 필요가 있음

- 웹 페이지의 변경 이력 활용
- 우선순위를 활용하여, 중요한 페이지는 좀 더 자주 재수집